# myapp/views/articles.py
from myapp.models import BlogArticle
from myapp.permissions import IsAdminOrReadOnly
from myapp.views.base import BaseModelViewSet
from rest_framework import viewsets
from bs4 import BeautifulSoup 
import re
from openai import OpenAI
from django.conf import settings
from pinecone import Pinecone
from rest_framework.response import Response
from rest_framework import status
from rest_framework.generics import ListAPIView
from rest_framework.filters import SearchFilter
from rest_framework.permissions import AllowAny
from ..serializers import (
    TagSerializer,
    UploadedFileReadSerializer, UploadedFileWriteSerializer,
    BlogArticleReadSerializer, BlogArticleWriteSerializer,
)
from myapp.serializers.article import BlogArticleSerializer


# BlogArticleViewSet ã«è¿½åŠ 
class BlogArticleViewSet(BaseModelViewSet):
    queryset = BlogArticle.objects.all().order_by("-created_at")
    permission_classes = [IsAdminOrReadOnly]
    
    
    def create(self, request, *args, **kwargs):
       body = request.data.get("body", "")
       text_only = BeautifulSoup(body, "html.parser").get_text()
       cleaned_text = re.sub(r"\s+", " ", text_only).strip()
       
       response = super().create(request, *args, **kwargs)
       article_id = response.data.get("id")
       
       chunks = chunk_text(cleaned_text, chunk_size=200, overlap=50)
       client = OpenAI(api_key=settings.OPENAI_API_KEY)
       pc = Pinecone(api_key=settings.PINECONE_API_KEY)
       index = pc.Index("my-index")
       
       for i, chunk in enumerate(chunks):
            emb = client.embeddings.create(
                input=chunk,
                model="text-embedding-3-small"
            )
            vector = emb.data[0].embedding

            index.upsert(vectors=[{
                "id": f"{article_id}-{i}",  # â† "è¨˜äº‹ID-ãƒãƒ£ãƒ³ã‚¯ç•ªå·"
                "values": vector,
                "metadata": {"text": chunk}
            }])

       return response
   
    def destroy(self, request, *args, **kwargs):
        instance = self.get_object()
        article_id = instance.id  # â† DBä¸Šã®IDã‚’å–å¾—

        # Pinecone ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        client = OpenAI(api_key=settings.OPENAI_API_KEY)
        pc = Pinecone(api_key=settings.PINECONE_API_KEY)
        index = pc.Index("my-index")

        # ğŸ”¹ ã¾ãšå¯¾è±¡è¨˜äº‹ã«å¯¾å¿œã™ã‚‹å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’å‰Šé™¤ã™ã‚‹
        # ã“ã“ã§ã¯ä¾¿å®œä¸Š 0ã€œ99 ã¾ã§ã‚’å‰Šé™¤å¯¾è±¡ã¨ã™ã‚‹ï¼ˆå¿…è¦ã«å¿œã˜ã¦ä¸Šé™ã‚’æ±ºã‚ã‚‹ï¼‰
        ids_to_delete = [f"{article_id}-{i}" for i in range(100)]
        index.delete(ids=ids_to_delete)

        # ğŸ”¹ DBã‹ã‚‰è¨˜äº‹ã‚’å‰Šé™¤
        self.perform_destroy(instance)
        return Response(status=status.HTTP_204_NO_CONTENT)
    
    def update(self, request, *args, **kwargs):
        # 1. æ›´æ–°å¯¾è±¡ã®è¨˜äº‹ã‚’å–å¾—
        partial = kwargs.pop("partial", False)
        instance = self.get_object()
        serializer = self.get_serializer(instance, data=request.data, partial=partial)
        serializer.is_valid(raise_exception=True)
        self.perform_update(serializer)

        article_id = serializer.instance.id
        body = serializer.validated_data.get("body", "")

        # 2. æœ¬æ–‡ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        text_only = BeautifulSoup(body, "html.parser").get_text()
        cleaned_text = re.sub(r"\s+", " ", text_only).strip()

        # 3. Pinecone ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæº–å‚™
        client = OpenAI(api_key=settings.OPENAI_API_KEY)
        pc = Pinecone(api_key=settings.PINECONE_API_KEY)
        index = pc.Index("my-index")

        # 4. æ—¢å­˜ãƒ™ã‚¯ãƒˆãƒ«å‰Šé™¤ï¼ˆè¨˜äº‹IDã§å§‹ã¾ã‚‹ã‚‚ã®ã‚’å…¨éƒ¨æ¶ˆã™ï¼‰
        # namespace ã‚’ä½¿ã£ã¦ã„ãªã„å ´åˆã¯ã€ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’ä¿å­˜ã—ã¦ãŠã„ã¦ range ã§åˆ—æŒ™ã™ã‚‹æ–¹ãŒå®‰å…¨ã§ã™
        # ç°¡æ˜“çš„ã«ã¯ delete(filter=...) ã‚’ä½¿ã†
        index.delete(filter={"article_id": str(article_id)})

        # 5. ãƒãƒ£ãƒ³ã‚¯åŒ–
        chunks = chunk_text(cleaned_text, chunk_size=200, overlap=50)

        # 6. Embedding ã‚’ä½œæˆ & Pinecone ã«ä¿å­˜
        vectors = []
        for i, chunk in enumerate(chunks):
            emb = client.embeddings.create(input=chunk, model="text-embedding-3-small")
            vectors.append({
                "id": f"{article_id}-{i}",
                "values": emb.data[0].embedding,
                "metadata": {"text": chunk, "article_id": str(article_id)}
            })
        index.upsert(vectors=vectors)

        return Response(serializer.data, status=status.HTTP_200_OK)

    def get_serializer_class(self):
        if self.action in ["create", "update", "partial_update"]:
            return BlogArticleWriteSerializer
        return BlogArticleReadSerializer
    
def chunk_text(text: str, chunk_size: int = 200, overlap: int = 50) -> list[str]:
    """
    æ–‡å­—åˆ—ã‚’ chunk_size ã”ã¨ã«åˆ†å‰²ã—ã€overlap ã ã‘é‡è¤‡ã‚’æŒãŸã›ã‚‹ã€‚
    æœ«å°¾ã®ä½™ã‚ŠãŒã‚ã‚Œã°æœ€å¾Œã® chunk_size åˆ†ã‚’è¿½åŠ ã™ã‚‹ã€‚
    """
    chunks = []
    start = 0
    text_length = len(text)

    while start < text_length:
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)

        if end >= text_length:
            break

        start = end - overlap  # overlap åˆ†æˆ»ã£ã¦æ¬¡ã®ãƒãƒ£ãƒ³ã‚¯é–‹å§‹

    return chunks


class BlogArticleFilterView(ListAPIView):
    authentication_classes = ()
    permission_classes = (AllowAny,)
    serializer_class = BlogArticleSerializer
    filter_backends = [SearchFilter]
    search_fields = ["title", "body"]  # â† ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢å¯¾è±¡

    def get_queryset(self):
        queryset = BlogArticle.objects.all()
        tag = self.request.query_params.get("tag")
        if tag:
            queryset = queryset.filter(tags__name=tag)
        return queryset
